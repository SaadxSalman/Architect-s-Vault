# Gemini-Game ğŸ®

An AI agent for video games that learns and adapts like a human player. Gemini-Game doesn't rely on scripted behavior but develops its own strategies, providing a truly dynamic and unpredictable opponent that offers a fresh challenge with every playthrough.

-----

## âœ¨ Features

  * **Human-like Adaptability:** Learns from gameplay experience to develop new strategies and counter-tactics.
  * **Perceptual Awareness:** A **Perception Agent** uses a **vision model** to directly interpret the game state from the screen, making it game-engine independent.
  * **Strategic Planning:** A **Strategy Agent** uses a large-scale model like **Gemma-3** for high-level strategic planning and decision-making.
  * **Reinforcement Learning:** A **Learning Agent** updates the model based on the outcomes of its actions, improving its performance over time.
  * **High-Performance Execution:** The core logic is built with **Rust** for real-time, low-latency execution, ensuring the agent can keep up with fast-paced games.
  * **Vector-Based State Representation:** Creates a specialized **embedding space** for game states and actions, facilitating efficient reinforcement learning.

-----

## âš™ï¸ Tech Stack

#### 1. Core Engine (The "Body")

* **Language:** **Rust** (Edition 2024) â€” Chosen for memory safety and zero-cost abstractions during high-frequency game loops.
* **Perception:** **OpenCV (Rust Bindings)** â€” Used for real-time frame capturing and basic image preprocessing (resizing to  for Gemma-3 compatibility).
* **Input Simulation:** **Enigo** â€” Simulates low-level OS events for mouse and keyboard without being detected by basic anti-cheat software.
* **Networking:** **Tokio + Reqwest** â€” Asynchronous runtime to handle non-blocking API calls to the Brain-API.

#### 2. Intelligence Layer (The "Brain")

* **Strategic Model:** **Gemma-3 (4B or 12B variant)** â€” A multimodal model that natively understands images and text. It processes game frames as "soft tokens" to generate high-level strategy.
* **Learning Framework:** **GRPO (Group Relative Policy Optimization)** â€” Implemented in Python via the **TRL (Transformer Reinforcement Learning)** library.
* *Why GRPO?* It eliminates the need for a separate "Value Model," making it 50% more memory-efficient than PPO for training gaming agents on a single GPU.


* **Inference:** **FastAPI + vLLM** â€” Provides a high-throughput OpenAI-compatible endpoint for the Rust core.

#### 3. Orchestration & Data (The "Memory")

* **Runtime:** **Node.js (v22+)** with **TypeScript**.
* **Database:** **MongoDB** â€” Stores "Decision Objects" which contain the state (), the action (), the raw "thought" from Gemma-3, and the reward () used for GRPO.
* **Real-time Bridge:** **Socket.io** â€” Streams the agent's internal reasoning (the `<think>` tags) from the backend directly to the dashboard.

#### 4. Web Dashboard (The "Interface")

* **Framework:** **Next.js 15** (App Router).
* **Styling:** **Tailwind CSS** + **Shadcn/UI** â€” For a high-performance, dark-themed "Command Center" aesthetic.
* **Visualization:** **Recharts** â€” To plot reward curves and "Confidence" levels of the agent in real-time.

---

### ğŸ“Š Summary Table

| Layer | Technology | Primary Function |
| --- | --- | --- |
| **Execution** | Rust |  screen capture & input |
| **Cognition** | Gemma-3 | Visual reasoning & Strategy planning |
| **Optimization** | GRPO | Learning from group-relative rewards |
| **Storage** | MongoDB | Logging trajectory data for training |
| **Monitoring** | Next.js | Live "Thought Stream" & Manual Override |

-----

## ğŸš€ Getting Started

### Prerequisites

  * Rust
  * Python 3.10+ (for training and model inference)
  * Access to the Gemma-3 model

### Installation

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/saadsalmanakram/Gemini-Game.git
    cd Gemini-Game
    ```
2.  **Build the Rust core:**
    ```bash
    cargo build --release
    ```
3.  **Set up the training environment:**
    Follow the instructions in the `training/` directory to install the necessary Python libraries and configure the reinforcement learning environment.

### Configuration

Create a `.env` file to store API keys and other environment variables required for running the agent.

### Usage

Run the main executable and point it to the game's video stream to begin the real-time analysis and gameplay.

-----

Here is the finalized, comprehensive file structure for **Gemini-Game**. This organization separates the high-performance Rust core, the Python AI services, the Node.js orchestration layer, and the Next.js frontend into a clean, professional monorepo.

### ğŸ“‚ Project Structure

```text
Gemini-Game/
â”œâ”€â”€ core-engine/                # RUST: High-performance Execution
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.rs             # Agent orchestrator & Loop
â”‚   â”‚   â”œâ”€â”€ perception.rs       # OpenCV Screen capture & Vision API client
â”‚   â”‚   â”œâ”€â”€ controller.rs       # Input simulation (Keyboard/Mouse)
â”‚   â”‚   â””â”€â”€ state_bridge.rs     # HTTP/WS Client to send telemetry to Brain-API
â”‚   â”œâ”€â”€ Cargo.toml              # Dependencies: opencv, enigo, tokio, reqwest
â”‚   â””â”€â”€ .env                    # Local Rust configs
â”‚
â”œâ”€â”€ brain-api/                  # NODE.JS/TS: Orchestration & Data
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â””â”€â”€ Session.ts      # MongoDB Schema (Decisions, Thoughts, Rewards)
â”‚   â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â”‚   â””â”€â”€ websocket.ts    # Socket.io setup for Dashboard syncing
â”‚   â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”‚   â”œâ”€â”€ telemetry.ts    # Receives data from Rust
â”‚   â”‚   â”‚   â””â”€â”€ reward.ts       # Endpoint for Manual/AI feedback
â”‚   â”‚   â””â”€â”€ server.ts           # Express entry point
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ dashboard/                  # NEXT.JS: Real-time UI
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”‚   â”œâ”€â”€ page.tsx        # Main Live Monitor View
â”‚   â”‚   â”‚   â””â”€â”€ layout.tsx      # Global Styles & Providers
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ThoughtStream.tsx # Scrolling list of Gemma-3 thoughts
â”‚   â”‚   â”‚   â”œâ”€â”€ RewardButton.tsx  # Feedback buttons for GRPO
â”‚   â”‚   â”‚   â””â”€â”€ StatsChart.tsx    # Recharts for Health/Performance
â”‚   â”‚   â””â”€â”€ lib/
â”‚   â”‚       â””â”€â”€ socket-client.ts # Socket.io initialization
â”‚   â”œâ”€â”€ tailwind.config.ts
â”‚   â””â”€â”€ next.config.js
â”‚
â”œâ”€â”€ models/                     # PYTHON: AI Inference & Learning
â”‚   â”œâ”€â”€ inference_server.py     # FastAPI: Gemma-3 & Vision Model server
â”‚   â”œâ”€â”€ training_agent.py       # GRPO logic: Reward calculation & weight updates
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ embeddings.py       # Custom vector space logic
â”‚   â””â”€â”€ requirements.txt        # torch, transformers, fastapi, pymongo
â”‚
â”œâ”€â”€ .env                        # Global: API Keys (GEMMA_API_KEY, MONGO_URI)
â”œâ”€â”€ docker-compose.yml          # Optional: To spin up MongoDB and API quickly
â””â”€â”€ README.md                   # Project documentation

```

---